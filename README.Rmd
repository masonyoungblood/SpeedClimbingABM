---
title: "Speed Climbing ABM"
author: "Mason Youngblood"
output: github_document
---

```{r echo=FALSE, fig.align="center", out.width="70%"}
knitr::include_graphics("https://helios-i.mashable.com/imagery/articles/03XKxYMwkNiZJGiHUu2FWnw/hero-image.fill.size_1248x702.v1628089817.png")
```

This agent-based model simulates a dynamic population of professional speed climbers, and incorporates parameters for athletic improvement, innovation of "beta" (or route sequence), and copying of other climbers' beta.

## Athletic Improvement

Athletic improvement is simulated using a bounded exponential function controlled by three parameters: `rate_m`, `rate_sd`, and `min`. `rate_m` controls the mean exponential rate across all climbers, `rate_sd` controls the standard deviation of the exponential rate to introduce variation in ability, and `min` controls the asymptotic lower bound. The result of this function is an `athletic_improvement` index for each climber over time (x-axis). Below is an example with a `rate_m` of 2, a `rate_sd` of 0.2, and a `min` of 0.4.

```{r}
#bounded exponential function
bounded_exp <- function(x, rate, min){
  return((1-min)*(rate/rate^x)+min)
}

#generate values
x <- 1:12
rates <- truncnorm::rtruncnorm(100, a = 1, mean = 2, sd = 0.2)
y <- sapply(1:length(rates), function(h){bounded_exp(x, rates[h], 0.4)})

#plot
par(mar = c(4, 4, 1, 1))
matplot(x, y, type = "l", xlab = "Timestep", ylab = "Athletic Improvement", ylim = c(0, 1), col = scales::alpha("black", 0.2), lty = 1)
```

```{r echo=FALSE}
#to inform lower bound of prior for improve_min
#min(data$time[which(data$year == max(data$year))])/min(data$time[which(data$year == min(data$year))])

#to inform upper bound of prior for improve_min
#M: 2007 record is 15.4, 2019 record is 5.49 (Qixin Zhong, World Cup, Xiamen, https://youtu.be/pJKVOWApsEU?t=1616) [6 skipped]
#W: 2007 record is 23.01, 2019 record is 7.1 (Yiling Song, World Cup, Chongqing, https://youtu.be/lBf2lp7OxnY?t=2333) [5 skipped]
#(5.49/14)/(15.4/20)
#(7.1/15)/(23.01/20)

#convenience sample of 20 men from 2019, number of skips
#https://www.youtube.com/watch?v=6_TrT95-hLo
#median(c(6, 5, 4, 5, 5, 6, 5, 5, 5, 5, 6, 5, 3, 5, 5, 5, 5, 6, 4, 4))
#(median(data$time[which(data$gender == "M" & data$year == 2019)])/15)/(median(data$time[which(data$gender == "M" & data$year == 2007)])/20)

#convenience sample of 20 women from 2019, number of skips
#https://www.youtube.com/watch?v=Ofcs3A0Ql2o
#median(c(4, 5, 5, 5, 5, 3, 4, 5, 5, 4, 3, 5, 5, 3, 5, 5, 5, 4, 5, 5))
#(median(data$time[which(data$gender == "W" & data$year == 2019)])/15)/(median(data$time[which(data$gender == "W" & data$year == 2007)])/20)
```

In each timestep, a climbers current record comes from multiplying the time per handhold by this `athletic_improvement` index. After the first timestep, new climbers entering the population will have their distribution of `athletic_improvement` indices divided by the `athletic_improvement` value from the timestep that they enter. In this way, a climber who enters the population with a lower climbing time will follow the same general improvement trajectory as everyone else in the population.

## Beta & Reference Times

Now, how do we use these distributions in combination with hold sequences? First, let's look at a diagram of the standardized speed wall.

```{r, echo=FALSE, fig.align="center", out.width="65%"}
knitr::include_graphics("https://www.kindpng.com/picc/m/592-5929143_speed-climbing-wall-sketch-speed-climbing-route-map.png")
```

As you can see, the standardized speed wall has a total of 20 hand holds and 11 foot holds. Speed climbers often "smear" their feet on the wall or use hand holds for feet, so we will only be modeling the time spent on hand holds. Each climber will be initialized with a vector of their beta, or a TRUE/FALSE for whether they use each hand hold in the route, along with a vector of sequence ratios. The sequence ratios will be drawn from a truncated normal distribution with a lower bound at 0, a mean of 1, and a standard deviation parameter that controls the initial variation in times across holds. The actual amount of time spent on each hold, then, will be these sequence ratios multiplied by an initial reference climbing time per hold (initially their starting climbing time divided by the number of holds). For now the beta vectors will start out as all TRUE, so that all climbers start out using every hold in the route. Here is an example of how the beta and sequence ratio vectors are initialized.

```{r}
#read in grid of holds and convert to meters
grid <- read.csv("grid.csv")
grid <- grid/1000

#euclidean distance function
euclidean <- function(x, skips){
  if(skips > 0){return(sqrt((grid$x[x+skips] - grid$x[x-skips])^2 + (grid$y[x+skips] - grid$y[x-skips])^2))}
  if(skips == 0){return(sqrt((grid$x[x] - grid$x[x-1])^2 + (grid$y[x] - grid$y[x-1])^2))}
}

#set number of holds
n_holds <- 20

#get distances between holds
dists <- sapply(1:n_holds, function(x){euclidean(x+1, 0)})

#set initial mean speed
init_time <- 18

#set probability of initial beta holds at 1 (all holds on the route)
beta_true_prob <- 1

#set parameter controlling the SD of sequence ratios
sd_multiplier <- 0.5

#initialize starting beta
beta <- sample(c(TRUE, FALSE), n_holds, prob = c(beta_true_prob, 1-beta_true_prob), replace = TRUE)

#initialize sequence ratios
seq_ratios <- truncnorm::rtruncnorm(n_holds, a = 0, mean = 1, sd = sd_multiplier)

#sort sequence ratios to match the distance order of the climbing holds
seq_ratios <- sort(seq_ratios)[rank(dists, ties.method = "first")]

#print the beta and climbing time vectors
beta
(init_time/n_holds)*seq_ratios
```

This `sd_multiplier` value of 0.5 generates a distribution of times per hold that is similar to the example distribution in [Reveret et al. (2020)](https://www.frontiersin.org/articles/10.3389/fpsyg.2020.02188/full) (see below), and is close to the variation in times per hold observed in lead climbing [(Seifert et al., 2020)](https://www.tandfonline.com/doi/full/10.1080/14763141.2020.1830161). A more recent study that estimated times per hold for two high-level climbers in the 2019 IFSC World Cup suggests that an `sd_multiplier` value of 0.33 may be more appropriate [(Pandurevic et al., 2022)](https://www.mdpi.com/1424-8220/22/6/2251), but in exploratory analyses the posterior for this parameter converged to 0.5. We will make a simplifying assumption and use 0.5 for all of our simulations.

```{r, echo=FALSE, fig.asp=0.4}
#get cumulative climbing times
cum_num <- cumsum(c(0, (init_time/n_holds)*seq_ratios))

#restructure and plot
to_plot <- data.frame(x = unlist(sapply(1:(length(cum_num)-1), function(x){seq(cum_num[x], cum_num[x+1], by = 0.01)})),
                      y = unlist(sapply(1:(length(cum_num)-1), function(x){rep(x, length(seq(cum_num[x], cum_num[x+1], by = 0.01)))})))
par(mar = c(4, 4, 1, 1))
plot(to_plot$x, to_plot$y, type = "l", xlab = "Time (s)", ylab = "Hold #")
```

In each timestep, each climber has a certain `innov_prob` probability of innovation. Innovations are changes to the beta of the route, in this case flipping one of the booleans of the `beta` vector from TRUE to FALSE. Not all boolean flips are possible. We will include a parameter `max_dist` that controls the maximum travel distance (Euclidean distance in meters) that a climber can travel after skipping a hold. To our knowledge, nobody has successfully skipped three or more holds in speed climbing, so an appropriate prior will be chosen to reflect this. The first hold can never be skipped, because every climber is required to start on it. The Euclidean distance for the last hold will be the distance between the second-to-last (or third-to-last) hold and the buzzer.

Below are the distributions of distances between holds that are one and two holds apart ...

```{r, echo=FALSE, fig.asp=0.4}
#get min and max distances for prior, and plot...
min_dist <- max(sapply(1:n_holds, function(x){euclidean(x+1, 0)}))
max_dist <- max(sapply(3:(nrow(grid)-2), function(x){euclidean(x, 2)}))
par(mar = c(4, 4, 1, 1))
hist(sapply(2:(nrow(grid)-1), function(x){euclidean(x, 1)}), breaks = 10, main = "", xlab = "Distance (m)", xlim = c(0, 4))
hist(sapply(3:(nrow(grid)-2), function(x){euclidean(x, 2)}), breaks = 10, main = "", xlab = "Distance (m)", xlim = c(0, 4))
```

Among the available holds within `max_dist`, the probability of innovating a hold will be based on two things: (1) the distance between the adjacent holds, and (2) the ratio between the original path distance and the new path distance. The first of these reflects a preference for skipping holds that lead to smaller gaps in the route, and the second reflects a preference for skipping holds that make the path more direct. For both measures, we will rank the possible holds to skip in ascending order by the distance ($R_{dist}$) and path ratio ($R_{ratio}$), invert them, and raise them to the power of parameters `constraint_a` and `constraint_b`. So, the random sampling of holds to skip will be weighted by the following:

$$(1 / R_{dist})^{constraint_{a}} * (1 / R_{ratio})^{constraint_{b}}$$

In other words, if skipping a hold means traversing a shorter and more direct distance, then that hold will be more likely to be skipped.

See `SpeedClimbingABM.R` for more details.

```{r, echo=FALSE, eval=FALSE}
#fall rate over time
orig_data <- read.csv("~/Documents/Work/Summer_2021/Speed Climbing/speed_climbing_data/speedclimbing_results.csv")
sapply(2007:2019, function(x){length(which(orig_data$score[which(haiii$Year == x)] %in% c("Fall", "FALL", "fall")))/length(orig_data$score[which(orig_data$Year == x)])})
```

## Social Learning

In each timestep, each climber also has a certain `learn_prob` probability of copying the beta of another climber. When a climber copies another climber, they only have access to the top `n_top` fastest climbers in the current timestep. They "try out" all of the betas of the fastest climbers that are different from their own beta, and if one of them yields a faster time then they overwrite their current `beta` and `seq_ratios` with those of better beta. See `SpeedClimbingABM.R` for details.

## Population Size & Turnover

In the original version of the model we did not use all available information about when specific climbers entered the sport, left the sport, etc. This version was far too stochastic to use for inference, so we are now incorporating this information explicitly into the model. First let's take a look at the data:

```{r echo=FALSE}
load("data.RData")
data.table::data.table(data)
```

Each row is an climber in a particular year with their current record. When a climber first enters the sport we will initialize them with their current record in that year, and then we will simulate innovation, learning, and athletic improvement from that baseline until they eventually leave the sport. In the cases when climbers' have gaps in their careers we will treat them as separate cascades by re-initializing their current record when they re-enter the sport and simulating change from there. Climbers who only appear in the dataset once be initialized with their current record in the year they appear and will disappear in the next year with no simulated improvement (see below).

```{r echo=FALSE}
par(mar = c(4, 4, 1, 1))
hist(as.numeric(sort(table(data$athlete), decreasing = TRUE)), main = NULL, xlab = "# of Years")
```

To do this, let's create a new `pop_data` object that includes all of the information we need. Each row corresponds to a continuous sequence of years: the first column is the climbers' ID, the second is their starting year, the third is their end year, and the fourth is their best time in the starting year.

```{r echo=FALSE}
#get all unique climbers
uniq_climbers <- unique(data$athlete)

#separate continuous sequences of years
seqs <- lapply(uniq_climbers, function(x){split(data$year[which(data$athlete == x)], cumsum(seq_along(data$year[which(data$athlete == x)]) %in% (which(diff(data$year[which(data$athlete == x)]) > 1) + 1)))})

#for each unique climber, iterate through their sequences, and and extract their ID, start year, end year, and time in start year (separate row per sequence)
pop_data <- data.table::data.table(do.call(rbind, lapply(1:length(uniq_climbers), function(i){
  t(sapply(1:length(seqs[[i]]), function(j){
    c(uniq_climbers[i], min(unlist(seqs[[i]][j])), max(unlist(seqs[[i]][j])), data$time[which(data$athlete == uniq_climbers[i] & data$year == min(unlist(seqs[[i]][j])))])
    }))
  })))
colnames(pop_data) <- c("ID", "start", "end", "time")
pop_data

#remove temp objects
rm(list = c("seqs", "uniq_climbers"))
```

After the first timestep, each new climber that joins the population will be initialized with a random `seq_ratios` and `beta` drawn from an existing climber. See `SpeedClimbingABM.R` for details.

## Interaction Effects

For our study, we want to add some interaction effects between innovation, social learning, ranking, and population size. More specifically, we want to innovation and social learning change with climbers' current rankings and with population size. To do this, we will adjust the mean innovation and social learning rates of the population with the following two equations for innovation and social learning, respectively:

$$logit(\mu) = logit(\mu_{avg}) + t_{scale} * {\phi} + p_{scale} * {\omega}$$

$$logit(\lambda) = logit(\lambda_{avg}) + t_{scale} * {\epsilon} + p_{scale} * {\sigma}$$

The calculations are done on the logit scale so that everything remains between 0 and 1. In each case there are three parameters in play. For innovation ($\mu$) there is the population average ($\mu_{avg}$), the effect of a climber's record time ($\phi$), and the effect of population size ($\omega$). The effects of time and population size are computed as follows: (1) all values are scaled and centered with a mean of 0 and standard deviation of 1, (2) the scale values are multiplied by number between -1 and 1, where the sign and absolute value control the direction and strength of the effect, respectively, and (3) the values are the multiplied by the logit-transformed innovation rate. Social learning is computed identically.

## Test Run

The ABM functions are in the `SpeedClimbingABM.R` file. Please refer to the functions in this file for details.

```{r}
source("SpeedClimbingABM.R")
```

Let's do a test run of this model based on the observed data from the men in the population.

```{r}
load("data.RData")
pop_data <- pop_data[which(data$gender[match(pop_data$ID, data$athlete)] == "M"), ]
data <- data[which(data$gender == "M"), ]
```

First we need the observed population sizes, leave probabilities, and initial climbing times.

```{r}
#get years
years <- sort(unique(data$year))

#population sizes
n <- unlist(lapply(1:length(years), function(x){nrow(data[which(data$year == years[x]), ])}))
```

Now let's run the model with an initial population size of `r n[1]`, a 0.2 probability of learning from the top 20 climbers, a 0.2 probability of innovation, and `max_dist` = 3. The `improve_rate_m` of athletic improvement will be 2, the `improve_rate_sd` will be 0.2, and the `min` improvement possible will be 0.4. `bw` and `ylim`, control the density bandwidth and y-axis limit in the plot, respectively. `sum_stats` controls whether summary statistics are calculated from the output, `plot` controls whether the output is plotted, and `bw` and `ylim` control the density bandwidth and y-axis limit of the plot, respectively.

```{r, fig.asp=0.6}
#store starting time
start <- Sys.time()

#run model
output <- SpeedClimbingABM(n = n, years = years, pop_data = pop_data, grid = grid,
                           n_holds = 20, beta_true_prob = 1, learn_prob = 0.2, n_top = 20,
                           innov_prob = 0.2, max_dist = 3, improve_rate_m = 2, improve_rate_sd = 0.2, improve_min = 0.4,
                           sum_stats = TRUE, plot = TRUE, bw = 0.6, ylim = 0.4)

#print run time
Sys.time() - start
```

In the above plot, each distribution (from right to left) is the distribution of `current_records` for climbers in the population in each timestep. The output of this ABM a table of the summary statistics (quantiles) from each timestep.

```{r}
output
```
